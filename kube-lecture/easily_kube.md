# 쉽게 시작하는 쿠버네티스
> 인프런 조훈님의 <쉽게 시작하는 쿠버네티스> 강의를 듣고 정리한 내용입니다.

## 1. 쿠버네티스 intro
### 쿠버네티스란?
* 컨테이너를 “관리해줍니다” 
* 오케스트레이션

### 도커가 뭘까?
* 하이퍼바이저를 제외할 수 있음
* 가상환경에 비해 더 많은 어플리케이션 (컨테이너)를 구동할 수 있음

### 도커를 먼저 배워야할까?
* 지금의 쿠버네티스 환경에서는 이미 많은 컨테이너들이 다 올라와 있어서.
* 스스로 굳이 만들어서 올릴 필요는 지금은 없기는 함.

### 쿠버네티스는 누가 만들었을까
* Google의 Borg 시스템을 CNCF에 판 다음에 관리함
* 즉, vendor에 종속성이 없다
	* 비용을 지불할 필요가 없음

### 쿠버네티스 배포 종류
* 관리형 쿠버네티스 : AWS , GCP, Azure 등
* 설치형 쿠버네티스 : rancher, open shift(red-hat)
* 네이티브 쿠버네티스 배포 : 구성형 쿠버네티스, 자유롭게 구성하고자 하는 경우 혹은 교육의 목적에 있는 경우.

## 2. 코드로 설치하는 쿠버네티스 랩 환경
### 웹에서 제공하는 쿠버네티스 환경
* 뭐 여러 웹에서 제공하는 쿠버네티스 환경들이 있음
* 세션에 종속적이거나 자유롭지 못한 단점들이 있음

### 코드로 구성하기
* vagrant -> virtual box
* brew install vagrant
* m1에서 virtual box 다행히 지원 됨. (최근 베타버전 릴리즈)

## 2. 배포를 통한 쿠버네티스 체험
### 배포를 통해 확인하는 파드
어플리케이션을 배포한다는 것? 
마스터 노드에서 워커노드에 nginx 어플리케이션을 설치하도록 명령을 보내는 것.
어플리케이션 배포의 구성 단위는 prod

Pod란?
컨테이너의 집합
쿠버네티스는 컨테이너를 관리하기 위한 도구잖아 = 오케스트레이션
대부분은 단일 컨테이너 (하나의 도커가 하나의 파드를 구성하는 경우가 많다)

Kubectl run nginx —image=nginx


### 파드를 외부에섣 접속하게 하는 서비스
172대의 Ip를 확인
로컬 머신에서 이 ip에 때리면 안감

쿠버네티스 클러스터 밖으로 나가려면 큰 대문을 통과해야함. 

1) 문을 날려버리던가 : 할수는 있는데 보안이 날라감
2) 문 밖에 안전한 구역을 만들어둠 : DMZ, 이 구역을 서비스(SVC)라고 부름.
ㄴ 실제로는 노드에 연결되는거지 파드에 연결되는건 아니고.
ㄴ 노드 포트
ㄴ 서비스가 노드 포트로 들어오고, 노드포트가 서로 통신을 하면서 파드를 찾아감


Kubectl expose pod nginx —type=NodePort —port=80
ㄴ 노출함

Kubectl get service
ㄴ NodePort 타입으로 노출되어 있다는 것을 확인할 수 있음

Kubectl get nodes -o wide
ㄴ internal ip를 확인할 수 있음
ㄴ internal이긴 하지만 지금 외부에서 접근이 가능함
ㄴ 해당 ip로 외부에서 접근하면 접근이 가능함

만약 파드가 죽으면 어떻게 될까?
ㄴ 파드가 여러 개 있을 수 있도록 준비하는 것이 디플로이먼트

### 파드와 디플로이먼트 차이
외부에서 접근할 수 있도록 했는데, 만약 파드가 죽어버리면 어떻게 될까?

현재상태)
서비스에서 워커노드 1,2,3번에 연결되어 있어서 확인함. 지금은 워커노드 1개에만 배포되어 있음. 

이제 하나가 문제가 생겨도 다른데서도 돌아가게 하고 싶음

디플로이먼트는 파드가 여러개 모여있는 단위군! 이라고 이해하면 좋을듯

현재 kubectl run으로는 파드 배포가 안됨
ㄴ kubectl create / kubectl apply로 가능함.
ㄴ kubectl apply는 파일을 이용해 배포하는 것
ㄴ kubectl run은 현실적으로 거의 사용하지 않음. 

Kubectl create deployment deploy-nginx(이름) —image=nginx 
ㄴ 여러개 배포한다매 하나밖에 안됐는데..?
ㄴ 명령 여러번을 통해서 배포할 수 있음
ㄴ 내부에 ReplicaSet이라는 것을 활용해서 도움을 받아야햄. 예전에는 이게 없어서. 이거의 디폴트 값을 3으로 늘리면 됨.
ㄴ pod 이름 중간에 있는 해시 값이 레플리카셋에 대한 이름임

Kubectl scale deployment deploy-nginx  —replica=3
ㄴ 두개가 더 늘어나서 3개로 스케일됨

파드의 배포 수를 쉽게 늘릴 수 있음. 줄이는 것도 가능함.

이제 이 디플로이먼트를 서비스로 노출한다는게 어떤 뜻인지? 
그리고 노드포트로 노출하는 것은 좋은 방법이 아님

### 외부로 노출하는 더 좋은 방법인 로드밸런서
일다 노드 포트로 디플로이먼트를 노출하기 위해서는
Kubectl expose deployment deploy-nginx —type=NodePort —port=80
여기서 서비스를 확인해보면 ip 확인이 가능

단, 노드의 ip를 그대로 알려주는 건 보안상 이슈가 있음. 대문에 비밀번호를 알려주는 것.
가장 좋은 방법은 로드밸런서 타입으로 설정해야 함.

#### 노드포트보다 로드밸런서보가 좋은 점
1. 노드 ip를 알려주지 않음. vip를 만들어서 알려주면 되기 때문에. 
2. 로드밸런서를 사용하면 가야 할 경로를 최적화하여 보내주도록 구현할 수 있음. 복잡할 뿐
3. 디플로이먼트를 로드밸런서로 배포
ㄴ kubectl apply  -f  ~/…./metallb.yaml
ㄴ metallb를 사용해서 생성하는 것
ㄴ kubectl expose deployment chk0-hn—type=LoadBalancer —port=80

### 배포한 것들 삭제하기
서비스?
대문이라기보단 정확하게는 “거실”
어떠한 곳을 거치기 위해서는 반드시 가야하는 곳.

### 쿠버네티스 구성 요소 확인
쿠버네티스 구성요소에 대한 이해가 있어야 실제로 운영할 수 있음. 
정말 많은 구성 요소들이 있지만… 이걸 다 설명하면 알 수가 없음. 이런것들로 이루어져 있군 정도로

#### 구역을 나누는 네임스페이스
지금까지 배포한건 기본 디폴트라는 ns에 있음.
근데 좀전에 본 여러가지 구성요소들은 ‘kube-system’이라는 네임스페이스에 있음.

서로의 구역이 나뉘어져 있는 단위.

네이티브 구성 요소들을 확인해봅시다.

Kubectl -get pods -n cube-system


### 쿠버네티스의 기본 철학
기본 시스템들이 kube-system 아래에 있는데 여기가 중요하더라. 주요한 요소들은 마스터노드에도 없고 별도로 너후고 관리하더라.

쿠버네티스가 생각하는 방식들을 알아야 함. 그래야 파드 배포시에 쿠버네티스 구성 요소들이 하는 일을 알 수 있음

#### 쿠버네티스의 기본 철학
MSA
마이크로서비스 아키텍쳐
ㄴ 하는 일들이 모두 분리되어 있음
ㄴ 각각의 구성 요소들이 각자 하는 일이 있음

1. Kubectl create pod를 때리면
2. Api 서버 & etcd에게 전달감.
ㄴ api 서버는 모든 것의 중심에 있고 굳건함. 큰 나무같음. 생성 요청을 받으면 오히려 생성 요청을 보내지 않음. 파드의 생성만 감시하고, 자기가 값만 가지고 있음
ㄴ 그러면 컨트롤러 매니저가 와서 확인하고감.
ㄴ api서버는 상태의 값만 가지고 잇음
ㄴ 샐운 파드가 워커노드에 들어갔는지 감시만 함
ㄴ 그러면 스케줄러가 와서 확인하고 워커노드에 넣고 감.

— 여기까지가 마스터노드
— 이제부터 큐블렛

3. 실제 생성은 워커노드가함
ㄴ 여기서 큐블렛이 함
ㄴ 워커노드에 있는 쿠버렛은 컨테이너 런타임을 통해서 파드의??
ㄴ 동작에 대한 관리만 하고, 컨테이너 런타임이 생성을 함.
ㄴ 그리고 상태 정보를 api서버에 전달함.

이게 명달을 전달하는게 아닌, api  서버는 상태값만 가지고 있고, 나머지들이 찾아와서 확인하는 느낌

=> 이게 바로 ‘선언적인 시스템’

추구하는 상태 <-> 현재 상태를 두고

계속 보면서 맞추려고 하는게 쿠버네티스의 가장 기본적인 알고리즘

상태변경 -> 감시 -> 차이발견 -> 상태변경 ……


#### API서버와 ETCD
Api 서버는 추구하는 값만 가지고 잇는데 이건 휘발될 수 있으니까, etcd라는 곳에 저장을 함.

매번 업데이트를 하면 etcd에 넣음. 이건 선언적 상태는 아님. 일반적으로 명령을 전달하는 방식

#### 두가지만 기억합시다
1. 선언적인 구조이며
2. 쿠버네티스의 구조에 있는 요소들은 자기 할일만 한다.

계속 추적하면서 맞추려고 하는게 쿠버네티스의 철학임

### 실제 쿠버네티스의 파드 배포 흐름
위에서 얘기한 부분을 실제 파드 배포 시나리오로 확인해봅시다.

[image:8C6ECB4E-E32A-4E54-81C3-04D8901E57FE-62309-00000DCDE9F46EF3/스크린샷 2023-08-07 오전 12.14.06.png]

1. Kubectl 명령을 때림
ㄴ api 서버에 파드든 서비스든 뭐든 명령을 내림
ㄴ 가장 먼저 하는건 etcd에 백업함. 여기에 1대1로 백업하기 때문에 백업도 가능함. Etcd 백업
ㄴ 컨트롤러 매니저가 api 서버를 보고 자기 값을 업데이트함
ㄴ 스케줄러가 파드가 워커노드에 밸런스되게 들어가게 함.

2. 워커노드
ㄴ 쿠버렛이 api 서버를 확인함
ㄴ 쿠버렛이 컨에티너 런타임에다가  파드를 생성하지 않겠니?
ㄴ 그렇게 생성된 파드들이 쿠버 프록시와 연결
ㄴ 사용자는 쿠버프록시와 통신
ㄴ 이러한 네트웍들은 쿠버네티스가 지원한다기 보단 이걸 선택할 수 있도록 해줌, 컨테이너 네트워크 인터페이스
ㄴ CALICO 등

여기서 가장 중요한건 API 서버라는 것. 모든 것의 시작이자 끝. 알파이자 오메가. 굉장히 중요한 요소임.

[image:E45C9974-81EB-462D-8CA7-E77E13FB8A7B-62309-00000DCEA548DFC4/스크린샷 2023-08-07 오전 12.16.16.png]

3. Code DNS
ㄴ ip는 우리가 지정할 수 없음. 확인만 할 수 있음.
ㄴ 따라서 거의 모두 core dns를 사용하고 있음.


## 섹션4. 문제를 통해 배우는 쿠버네티스
## 쿠버네티스 파드에 문제가 생겼다면?
쿠버네티스가 파드를 대하는 자세?
ㄴ 애완동물이 아님. 가축으로봄.
ㄴ 소중하게 다루지는 않음. 죽을수도 있지. 
ㄴ 파드는 어디로 옮겨지지 않음. 어디론가 가는 경우에는 반드시 삭제하고 다시 만듬

## 쿠버네티스 워커노드의 구성 요소에 문제가 생겼다면?
1. 대부분의 구성 요소들은 문제가 생겨도 빠르게 복구가 되지만,
통신하는걸 보면, ‘쿠버렛’에 문제가 생기는 경우에 바로 복구가 되지 않을 수 있음

Systemcrl stop kubelet
Systemctl status kubelet

2. 컨테이너런타임에 문제가 생기는 경우
Systemctl stop containerd
Systemctl status containerd

그럼 기존에 있던 애들은 어떻게 되나요? -> 5분정도동안 보고 evicted가 됨.

파드를 해당 워커노드에 배포할 수가 없음

3. 추가 배포를 통해 스케줄러 역할 확인
‘가능한 균등하게 함’  (best effort)

## 쿠버네티스 마스터노드 구성요소에 문제가 생겼다면?
1. kube-system
ㄴ kube-system 내에 있는 요소들도 파드인데, 이걸 삭제한다면, 삭제하더라도 다시 생성됨. 보호를 하고 있기 때문

2. Kubelet
ㄴ 마스터노드에 있는 kubelet을 중단하면 어떻게될까?
ㄴ kubelet을 삭제하고 스케줄러를 지우면?
ㄴ 쿠버렛이 죽으면 실제로 명령이 실행은 안되는 상태
ㄴ 만약 여기서 배포를 하면?
ㄴ 생성이 되고 있음
ㄴ 스케줄러때문에 스케일이 안되지 않을까?
ㄴ 실제로 별 영향을 안주네..?

1.20같은경우에는 도커를 썼어서 이게 죽으면 다 멈췃음. Api 서버까지 도달도 못해서.
근데 컨테이너d로 변경된 이후에는 안정적으로 운영이됨

단, 만약 마스터노드에서 누가 죽었을 때, 얘가 알아서 살아나야 하는데 컨테이너런타임이 죽어있으면 

## 쿠버네티스 오브젝트
쿠버네티스 오브젝트란?
추구하는 상태를 가지는 것.

상태?
추구하는 상태 vs 현재 상태

Kubectl edit deployment del-edit

Spec <- 추구하는 상태
Status <- 현재 상태

선언한 상태에 현재상태를 맞추기 때문에. 

## 쿠버네티스 기본 오브젝트
1. 파드
2. 서비스
3. 네암스페이스
4. 볼륨 <— new

볼륨?
ㄴ 파드는 언제든지 죽일수 있음.
ㄴ 데이터를 올리고 데이터를 추가한다고 했을 때 이 데이터는 볼륨에 붙여줘야함.

볼륨을 쓴다는 것은?
ㄴ 워커노드들이 다 한 곳을 바라봐야함.
ㄴ 가장 쉬운건 Nfs 시스템
ㄴ 


















